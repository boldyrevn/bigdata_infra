{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e251d0c-c310-4e13-8824-49339285b592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"py4j\").setLevel(logging.INFO)\n",
    "logging.getLogger(\"org.apache.spark\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d82e0fdc-ea28-4517-8ecd-5d29acbd84ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark with HDFS and Hive\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"hdfs://namenode:9000/user/hive/warehouse\") \\\n",
    "    .config(\"hive.metastore.uris\", \"thrift://hive-metastore:9083\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://namenode:9000\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"false\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.cores\", \"1\") \\\n",
    "    .config(\"spark.driver.memory\", \"1g\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "946d4bb9-1c67-435e-b260-ec7709fc2362",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.session.SparkSession"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b61d95f-c6e5-4721-9b02-ac58dc52f204",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o41.conf.\n: java.lang.IllegalStateException: LiveListenerBus is stopped.\n\tat org.apache.spark.scheduler.LiveListenerBus.addToQueue(LiveListenerBus.scala:92)\n\tat org.apache.spark.scheduler.LiveListenerBus.addToStatusQueue(LiveListenerBus.scala:75)\n\tat org.apache.spark.sql.internal.SharedState.<init>(SharedState.scala:115)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sharedState$1(SparkSession.scala:143)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.SparkSession.sharedState$lzycompute(SparkSession.scala:143)\n\tat org.apache.spark.sql.SparkSession.sharedState(SparkSession.scala:142)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sessionState$2(SparkSession.scala:162)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:160)\n\tat org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:157)\n\tat org.apache.spark.sql.SparkSession.conf$lzycompute(SparkSession.scala:185)\n\tat org.apache.spark.sql.SparkSession.conf(SparkSession.scala:185)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/IPython/core/formatters.py:344\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    342\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pyspark/sql/session.py:335\u001b[0m, in \u001b[0;36mSparkSession._repr_html_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_repr_html_\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;124m        <div>\u001b[39m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;124m            <p><b>SparkSession - \u001b[39m\u001b[38;5;132;01m{catalogImplementation}\u001b[39;00m\u001b[38;5;124m</b></p>\u001b[39m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124m            \u001b[39m\u001b[38;5;132;01m{sc_HTML}\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124m        </div>\u001b[39m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m--> 335\u001b[0m         catalogImplementation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.sql.catalogImplementation\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    336\u001b[0m         sc_HTML\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkContext\u001b[38;5;241m.\u001b[39m_repr_html_(),\n\u001b[1;32m    337\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pyspark/sql/session.py:413\u001b[0m, in \u001b[0;36mSparkSession.conf\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runtime configuration interface for Spark.\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \n\u001b[1;32m    404\u001b[0m \u001b[38;5;124;03mThis is the interface through which the user can get and set all Spark and Hadoop\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;124;03m:class:`pyspark.sql.conf.RuntimeConfig`\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_conf\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 413\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conf \u001b[38;5;241m=\u001b[39m RuntimeConfig(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conf\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pyspark/sql/utils.py:190\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    192\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o41.conf.\n: java.lang.IllegalStateException: LiveListenerBus is stopped.\n\tat org.apache.spark.scheduler.LiveListenerBus.addToQueue(LiveListenerBus.scala:92)\n\tat org.apache.spark.scheduler.LiveListenerBus.addToStatusQueue(LiveListenerBus.scala:75)\n\tat org.apache.spark.sql.internal.SharedState.<init>(SharedState.scala:115)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sharedState$1(SparkSession.scala:143)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.SparkSession.sharedState$lzycompute(SparkSession.scala:143)\n\tat org.apache.spark.sql.SparkSession.sharedState(SparkSession.scala:142)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sessionState$2(SparkSession.scala:162)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:160)\n\tat org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:157)\n\tat org.apache.spark.sql.SparkSession.conf$lzycompute(SparkSession.scala:185)\n\tat org.apache.spark.sql.SparkSession.conf(SparkSession.scala:185)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:833)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffff8bf5f010>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ddb757-fba9-4741-86eb-899959bc8e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .config(\"master\", \"yarn\") \\\n",
    "    .appName(\"new_spark\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748ce475-cf9b-454a-9f68-d79765a46938",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e44f8db-12a7-42c5-aaab-8fa52f8a5765",
   "metadata": {},
   "source": [
    "# Введение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4868e3bb-d495-490c-b950-54df81b97f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1, 2, 3, 4, 5]\n",
    "rdd = spark.sparkContext.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79686220-9f50-4093-9c0b-e854f8e920cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4878d03-f1dd-40cc-ac55-50b4a837e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd66704-88dd-46fd-bf4e-f0743e21c9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe43ec0-26c9-4896-a3d3-9af67a64e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.repartition(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df496a4-322b-4744-b67e-9b91ff8c805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f59255-5c52-4559-8940-b460d68a4573",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.repartition(2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cab3957-ca3c-4a30-8bb0-588426ed7e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_mapped = rdd.map(lambda x: x * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82344aaa-492b-4081-bba2-9c378c2b66be",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7721a181-8f31-49fc-8c8b-a43895c2c3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_mapped.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaecd5c7-4071-4389-84c4-f6767cd85548",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_filtered = rdd.filter(lambda x: x % 2 == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b70567-a464-41c1-97b2-102117790ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_filtered.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e11246d-9e65-42a9-8d2d-dee84bbe764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = rdd.groupBy(lambda x: \"even\" if x % 2 == 0 else \"odd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a0ce9e-ba5e-455e-87d6-1b835089cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80a053c-741d-47ce-a23f-f6f4ef9e60bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print({k: list(v) for k, v in grouped.collect()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bc94b4-197c-43d4-a6a0-3b9325607870",
   "metadata": {},
   "source": [
    "# Экшены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2e67bc-2eb9-4a65-a073-86db2f1fac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ffdcc6-a013-405f-bfa3-cf57309464c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048779e0-6f9e-45ef-b681-a0e4f78a4dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_2 = rdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b74714-a0ea-4ca8-9968-bb540c3ed97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efea2871-0ce2-40c3-9f4c-618fdc10f20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837cf58c-d766-463b-9565-2a79967be33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = rdd.reduce(lambda a, b: a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a43ea89-b16d-4c91-ba58-4894376126e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef785b0c-e6c0-4611-bb9f-1a2f39317abf",
   "metadata": {},
   "source": [
    "### Передаем данные на драйвер: \n",
    "\n",
    "- collect()\n",
    "- take()\n",
    "- count()\n",
    "- бродкаст-переменные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e071a5-b325-4605-80a3-b7bd0ed7cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1905dc6-c058-450d-a58f-07d702bd9afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcast_var = spark.sparkContext.broadcast([10, 20, 30, 40, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d45d89-30f2-459c-8545-2f7f918c3e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_with_broadcast = rdd.map(lambda x: x + broadcast_var.value[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f421dd41-5d19-4c0b-8d76-5f83de9fd637",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_with_broadcast.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ae0527-87aa-4040-acc0-519b17373606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350f8e8f-e6b3-4007-9d09-ccada0d9f9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = [randint(1, 15) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935671ea-9757-434a-a8c7-e31fbae58937",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adcf914-46af-4946-908e-b7fd75890e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_ = spark.sparkContext.parallelize(data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35788209-b304-4b35-a86d-d527acba4445",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da15c45-8306-4d30-9a95-113fa09e664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_.repartition(5).collect() # шафл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963d123b-8acc-42ec-a0af-62958cf3b67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_.coalesce(2).collect() # без шафла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc79acb2-db92-47e5-a653-b9a12f536c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb290772-2e15-43b5-b404-149bcea564c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96334a06-6b0c-4845-8a0b-6b9670655f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fa862c-d230-443a-b389-3e46ccaa4f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96aa96-93ed-43cb-819a-969d79756d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = rdd_.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00459237-123b-4c2f-8494-76030f1f7cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b21c20-3f00-4170-85a5-1544ea78c5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3994ce77-fa46-4d9d-aeeb-0a6e5d9fc880",
   "metadata": {},
   "source": [
    "### Объединение rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4696387-f0da-4355-a6f1-a7462f26891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = spark.sparkContext.parallelize([1, 2, 3]).repartition(1)\n",
    "rdd2 = spark.sparkContext.parallelize([4, 5, 6]).repartition(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5892f20d-d62a-49c2-9652-be63c7487d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "union_rdd = rdd1.union(rdd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6369e73f-e207-4858-af8a-1f1369f20461",
   "metadata": {},
   "outputs": [],
   "source": [
    "union_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63abb835-16ea-44d4-adf2-c9039566258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_pairs1 = spark.sparkContext.parallelize([(1, \"A\"), (2, \"B\"), (3, \"C\")])\n",
    "rdd_pairs2 = spark.sparkContext.parallelize([(1, \"X\"), (2, \"Y\"), (4, \"Z\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40807245-6a99-417e-8c6c-772ba0935e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_pairs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47c92c5-6660-4d97-8e17-cbecb97c93f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_pairs1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28808677-51b3-4c22-8861-ca8d31eb1ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_rdd = rdd_pairs1.join(rdd_pairs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbe9d4c-f7d6-4d0d-a552-885c82e95b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44396631-1ca2-471c-9667-fd0ad1d11ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbe0ee8-7303-42c3-ac38-3fcbcb4580eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_next = spark.sparkContext.parallelize([(1, \"Alice\"), (2, \"Bob\"), (3, \"Charlie\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dd471d-7fb5-4bfa-a341-619b403ee6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce87000-8e21-4164-b4fd-31a01a84ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(rdd_next, schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbce5a5b-c6cf-49c5-9284-740b60b66f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039da7ad-27b2-4804-b606-50b581fe0482",
   "metadata": {},
   "source": [
    "### Работа с JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f867ce-0e8f-47c6-bc99-ab4952cf5ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_rdd = spark.sparkContext.parallelize([\n",
    "    '{\"id\": 1, \"name\": \"Alice\"}',\n",
    "    '{\"id\": 2, \"name\": \"Bob\"}'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce12ecb-72cb-40ef-938a-b34c82086b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_j = spark.read.json(json_rdd)\n",
    "df_j.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aa8f77-e06f-411f-a6dd-dff2b1d253a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_j.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11147aa0-9ca7-4dc4-80a4-1516674de7d8",
   "metadata": {},
   "source": [
    "### WC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eec1677-fd7f-4018-b3f7-28e572facadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rdd = spark.sparkContext.parallelize([\n",
    "    \"Spark is awesome\",\n",
    "    \"Spark is fast\",\n",
    "    \"Hello Spark\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9927c53-86c7-44ef-9084-ebb114712210",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = (text_rdd\n",
    "               .flatMap(lambda line: line.split(\" \")) \n",
    "               .map(lambda word: (word, 1))           \n",
    "               .reduceByKey(lambda a, b: a + b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303f80a6-8a26-4678-ae2c-f4a021dc1978",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b442791-daca-4aaf-bf86-97962b7e6c88",
   "metadata": {},
   "source": [
    "### Вычисление среднего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382258f5-3d2b-4490-b789-f0ff4da32d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data = [(\"IT\", 100), (\"HR\", 80), (\"IT\", 120), (\"HR\", 90)]\n",
    "rdd = spark.sparkContext.parallelize(salary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3381a4b0-4576-4b26-94d1-6ff8426570ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (rdd\n",
    "          .mapValues(lambda x: (x, 1))               \n",
    "          .reduceByKey(lambda a, b: (a[0]+b[0], a[1]+b[1]))  \n",
    "          .mapValues(lambda x: x[0]/x[1]))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba6b8b2-19d8-4396-b657-7bc84dda084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (rdd\n",
    "          .mapValues(lambda x: (x, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b470b8f-5b08-4495-aa0a-311e3bc2a834",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9601a0d0-6c0c-4209-b383-1466169dd303",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ = result.reduceByKey(lambda a, b: (a[0]+b[0], a[1]+b[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce19d4c-f5f8-419c-a629-e9f1fdc96be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a620f4-d61f-44d0-85d5-baa8475bfca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result__ = result_.mapValues(lambda x: x[0]/x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fc2ac1-0926-4ba2-aafb-5cb13895da5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result__.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9018b3f9-046e-45a1-a1ad-09f39e090099",
   "metadata": {},
   "source": [
    "### flatMap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23480431-fb0b-4de2-9615-d42fd99ba8df",
   "metadata": {},
   "source": [
    "разбиение строк на слова "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6820bfc-9fbf-4538-bf2f-726b43d40f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [\"Hello world\", \"Apache Spark\", \"PySpark RDD\"]\n",
    "rdd = spark.sparkContext.parallelize(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211b2819-1d0d-43a8-be42-8dd596c5c277",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_rdd = rdd.flatMap(lambda line: line.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e28cd52-24a1-4776-94f2-a0d4c3d310ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(words_rdd.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc16faf-344f-4410-96b7-e90c862e4923",
   "metadata": {},
   "source": [
    "### Развертывание вложенных структур"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeabafd-ef72-4592-b7ac-61be49039f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(\"A\", [1, 2, 3]), (\"B\", [4, 5])]\n",
    "rdd = spark.sparkContext.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f78424-da8b-4c71-a5b7-ff30fc847b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened = rdd.flatMap(lambda x: [(x[0], num) for num in x[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7f6b66-f798-45a9-a4af-6879061521d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flattened.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa72df0-2eda-4d47-976f-c4d94577aab6",
   "metadata": {},
   "source": [
    "### Оптимизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d847305-9261-4690-97e8-e10f49b93519",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(\"A\", 10), (\"B\", 20), (\"A\", 30), (\"B\", 40)]\n",
    "rdd = spark.sparkContext.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2558a4-0723-4ad5-90c3-d1c268b512e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357363f8-764b-434c-8db9-dd0bf0cf0efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rdd.aggregateByKey(\n",
    "    (0, 0),                         # Нулевое значение\n",
    "    lambda acc, val: (acc[0] + val, acc[1] + 1),  # Локальная агрегация\n",
    "    lambda acc1, acc2: (acc1[0] + acc2[0], acc1[1] + acc2[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03c6e7c-84e1-4ff6-8159-9ecd57159cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2778a0cb-9705-46fa-8b0e-d8a4f0b8b4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rdd.combineByKey(\n",
    "    lambda value: (value, 1, value),                  # Создаем аккумулятор\n",
    "    lambda acc, value: (acc[0] + value, acc[1] + 1, max(acc[2], value)),\n",
    "    lambda acc1, acc2: (acc1[0] + acc2[0], acc1[1] + acc2[1], max(acc1[2], acc2[2])))\n",
    "\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a55ab9-7563-415e-ba9f-b82be4736e16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
